import os
import requests
import time
from tqdm import tqdm

# Th∆∞ m·ª•c l∆∞u file
baseline_folder = "pubmed_baseline_2025"
os.makedirs(baseline_folder, exist_ok=True)

# Base URL
base_url = "https://ftp.ncbi.nlm.nih.gov/pubmed/baseline/"

# C·∫•u h√¨nh
start_file = 1197
end_file = 1274
max_retries = 5  # s·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa n·∫øu l·ªói
retry_delay = 5  # gi√¢y ngh·ªâ gi·ªØa c√°c l·∫ßn th·ª≠ l·∫°i

# H√†m t·∫£i 1 file v·ªõi retry
def download_file(i):
    file_name = f"pubmed25n{i:04d}.xml.gz"
    file_url = base_url + file_name
    file_path = os.path.join(baseline_folder, file_name)

    if os.path.exists(file_path):
        print(f"{file_name} ƒë√£ t·ªìn t·∫°i, b·ªè qua...")
        return

    for attempt in range(1, max_retries + 1):
        try:
            print(f"B·∫Øt ƒë·∫ßu t·∫£i {file_name} (th·ª≠ l·∫ßn {attempt})")
            # TƒÉng timeout l√™n: 10 gi√¢y cho k·∫øt n·ªëi, 60 gi√¢y cho nh·∫≠n d·ªØ li·ªáu
            response = requests.get(file_url, stream=True, timeout=(10, 60))
            if response.status_code != 200:
                print(f"Kh√¥ng t√¨m th·∫•y file: {file_name}")
                return

            total_size = int(response.headers.get('content-length', 0))
            with open(file_path, "wb") as f, tqdm(
                total=total_size,
                desc=f"T·∫£i {file_name}",
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
                leave=True
            ) as bar:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))

            print(f"‚úÖ T·∫£i th√†nh c√¥ng: {file_name}")
            return  # t·∫£i xong th√¨ tho√°t kh·ªèi v√≤ng l·∫∑p retry

        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi t·∫£i {file_name} (l·∫ßn {attempt}): {e}")
            if attempt < max_retries:
                print(f"üîÅ Ch·ªù {retry_delay} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                time.sleep(retry_delay)
            else:
                print(f"‚õîÔ∏è B·ªè qua {file_name} sau {max_retries} l·∫ßn th·ª≠.")

# Ch·∫°y l·∫ßn l∆∞·ª£t t·ª´ file start ƒë·∫øn end
for i in range(start_file, end_file + 1):
    download_file(i)
import os
import requests
import time
from tqdm import tqdm

# Th∆∞ m·ª•c l∆∞u file
baseline_folder = "pubmed_baseline_2025"
os.makedirs(baseline_folder, exist_ok=True)

# Base URL
base_url = "https://ftp.ncbi.nlm.nih.gov/pubmed/baseline/"

# C·∫•u h√¨nh
start_file = 1
end_file = 1274
max_retries = 5  # s·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa n·∫øu l·ªói
retry_delay = 5  # gi√¢y ngh·ªâ gi·ªØa c√°c l·∫ßn th·ª≠ l·∫°i

# H√†m t·∫£i 1 file v·ªõi retry
def download_file(i):
    file_name = f"pubmed25n{i:04d}.xml.gz"
    file_url = base_url + file_name
    file_path = os.path.join(baseline_folder, file_name)

    if os.path.exists(file_path):
        print(f"{file_name} ƒë√£ t·ªìn t·∫°i, b·ªè qua...")
        return

    for attempt in range(1, max_retries + 1):
        try:
            print(f"B·∫Øt ƒë·∫ßu t·∫£i {file_name} (th·ª≠ l·∫ßn {attempt})")
            # TƒÉng timeout l√™n: 10 gi√¢y cho k·∫øt n·ªëi, 60 gi√¢y cho nh·∫≠n d·ªØ li·ªáu
            response = requests.get(file_url, stream=True, timeout=(10, 60))
            if response.status_code != 200:
                print(f"Kh√¥ng t√¨m th·∫•y file: {file_name}")
                return

            total_size = int(response.headers.get('content-length', 0))
            with open(file_path, "wb") as f, tqdm(
                total=total_size,
                desc=f"T·∫£i {file_name}",
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
                leave=True
            ) as bar:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))

            print(f"‚úÖ T·∫£i th√†nh c√¥ng: {file_name}")
            return  # t·∫£i xong th√¨ tho√°t kh·ªèi v√≤ng l·∫∑p retry

        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi t·∫£i {file_name} (l·∫ßn {attempt}): {e}")
            if attempt < max_retries:
                print(f"üîÅ Ch·ªù {retry_delay} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                time.sleep(retry_delay)
            else:
                print(f"‚õîÔ∏è B·ªè qua {file_name} sau {max_retries} l·∫ßn th·ª≠.")

# Ch·∫°y l·∫ßn l∆∞·ª£t t·ª´ file start ƒë·∫øn end
for i in range(start_file, end_file + 1):
    download_file(i)
