
import os
import pickle
import uuid
import time

import hashlib

def generate_hashed_uuid(vector, raw_uuid):
    h = hashlib.md5()
    h.update(str(vector).encode("utf-8"))
    h.update(str(raw_uuid).encode("utf-8"))
    return str(uuid.UUID(h.hexdigest()))

import weaviate
from tqdm import tqdm
import gc
import subprocess

# --- ThÃ´ng tin cáº¥u hÃ¬nh ---
input_dir = "embeddings"
container_name = "bioasq-weaviate-1"
collection_name = "PubMedAbstract"
SUB_BATCH_SIZE = 300

# --- HÃ m kiá»ƒm tra Weaviate Ä‘Ã£ sáºµn sÃ ng sau khi restart ---
def wait_for_weaviate_ready(max_wait_seconds=120):
    start_time = time.time()
    while True:
        try:
            client = weaviate.connect_to_local()
            if client.is_ready():
                return client
        except:
            pass

        if time.time() - start_time > max_wait_seconds:
            raise TimeoutError("Weaviate khÃ´ng khá»Ÿi Ä‘á»™ng láº¡i Ä‘Ãºng thá»i gian.")
        print("Chá» Weaviate khá»Ÿi Ä‘á»™ng láº¡i...")
        time.sleep(5)

# --- Báº¯t Ä‘áº§u tiáº¿n trÃ¬nh indexing ---
client = weaviate.connect_to_local()
collection = client.collections.get(collection_name)

#939-941 
for i in tqdm(range(939, 942), desc="Indexing files"):

    file = f"embeddings_{i:04d}.pkl.pkl"
    path = os.path.join(input_dir, file)

    if not os.path.exists(path):
        print(f"File khÃ´ng tá»“n táº¡i: {file}")
        continue

    with open(path, "rb") as f:
        data = pickle.load(f)

    total = len(data)
    success_count = 0
    fail_count = 0

    print(f"ğŸ“„ File {file} cÃ³ {total} vectors. Äang chia vÃ  upload theo lÃ´ {SUB_BATCH_SIZE}...")

    for start in tqdm(range(0, total, SUB_BATCH_SIZE), desc=f"â†’ File {file}", leave=False):
        end = min(start + SUB_BATCH_SIZE, total)
        sub_data = data[start:end]

        with collection.batch.dynamic() as batch:
            for obj in sub_data:
                try:
                    metadata = {
                        "page_content": obj["page_content"],
                        "pmid": obj["metadata"]["pmid"],
                        "title": obj["metadata"]["title"],
                        "abstract": obj["metadata"]["abstract"],
                        "chunk": obj["metadata"]["chunk"],
                    }

                    safe_uuid = generate_hashed_uuid(obj["vector"], obj["uuid"])

                    batch.add_object(
                        properties=metadata,
                        uuid=safe_uuid,
                        vector=obj["vector"]
                    )
                    success_count += 1

                except Exception as e:
                    print(f"Lá»—i khi thÃªm object UUID={obj.get('uuid', '??')}: {e}")
                    fail_count += 1

        failed_objects = collection.batch.failed_objects
        if failed_objects:
            print(f"{len(failed_objects)} lá»—i trong batch {start}-{end}. Lá»—i Ä‘áº§u tiÃªn:")
            print(failed_objects[0])
            fail_count += len(failed_objects)
        else:
            print(f"Batch {start}-{end} OK")

        del sub_data
        gc.collect()

    del data
    gc.collect()
    print(f"HoÃ n táº¥t indexing file: {file}")
    print(f"Tá»•ng vector trong file: {total}")
    print(f"ThÃ nh cÃ´ng: {success_count}")
    print(f"Tháº¥t báº¡i: {fail_count}")
    print(f"Tá»•ng Ä‘Ã£ xá»­ lÃ½: {success_count + fail_count}")

    # --- Restart container Ä‘á»ƒ giáº£i phÃ³ng RAM ---
    print("Stop container Ä‘á»ƒ giáº£i phÃ³ng RAM...")
    subprocess.run(["docker", "stop", container_name])
    time.sleep(60)  # Äá»£i RAM Ä‘Æ°á»£c há»‡ thá»‘ng giáº£i phÃ³ng (quan trá»ng)
    print("Start láº¡i container...")
    subprocess.run(["docker", "start", container_name])
    print("âœ… Container Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng láº¡i.")

# --- Káº¿t thÃºc ---
print("ÄÃ£ hoÃ n táº¥t indexing toÃ n bá»™ vectors vÃ o Weaviate.")
client.close()
